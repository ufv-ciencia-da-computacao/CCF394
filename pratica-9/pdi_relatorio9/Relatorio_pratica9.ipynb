{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introdução"
      ],
      "metadata": {
        "id": "FTQ_c0iRk8qZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grupo: Germano Barcelos (3873), Guilherme Melos (3882), Jhonata Miranda (3859)"
      ],
      "metadata": {
        "id": "LhkCGcATaSij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O reconhecimento de rostos é amplamente utilizado hoje em dia para segurança, reconhecimento facial em diversos dispositivos, processamento de imagens de pessoas, entre outras aplicações. Utilizando um algoritmo conhecido como Haar Cascade, iremos reconhecer em um vídeo alguns personagens conhecidos, com a obtenção das chamadas características de Haar. "
      ],
      "metadata": {
        "id": "TMxwT9wGagUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Haar Cascade"
      ],
      "metadata": {
        "id": "S3HbBYMjPDb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um classificador Haar, ou classificador em Haar cascade, é um programa de detecção de objectos de aprendizagem de máquina que identifica objectos numa imagem e num vídeo. \n",
        "\n",
        "O algoritmo pode ser explicado em quatro fases:\n",
        "\n",
        "1.   Cálculo das características de Haar\n",
        "2.   Criação de imagens integrais\n",
        "3.   Usando o Adaboost\n",
        "4.   Implementar classificadores em cascata\n",
        "\n",
        "É importante lembrar que este algoritmo requer muitas imagens positivas de rostos e imagens negativas de não-faces para treinar o classificador, à semelhança de outros modelos de aprendizagem de máquinas."
      ],
      "metadata": {
        "id": "LOoGJB9xPJtd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cálculo das características de Haar"
      ],
      "metadata": {
        "id": "-sLA16BhQlXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O primeiro passo é recolher as características de Haar. Uma característica Haar é essencialmente cálculos que são efectuados em regiões retangulares adjacentes, num local específico, numa janela de detecção. O cálculo implica somar as intensidades de píxeis em cada região e calcular as diferenças entre as somas. Seguem-se alguns exemplos de características de Haar."
      ],
      "metadata": {
        "id": "SfGztgVzQrnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1_yl-BqUzycbyfhPAzwWOddQ.webp](data:image/webp;base64,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)"
      ],
      "metadata": {
        "id": "Risf7i5cQ_oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas características podem ser difíceis de determinar para uma imagem grande. É aqui que entram em jogo as imagens integrais porque o número de operações é reduzido utilizando a imagem integral."
      ],
      "metadata": {
        "id": "z9tmI1fORCOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Criando imagens integrais"
      ],
      "metadata": {
        "id": "xTKHuDkCRINH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As imagens integrais aceleram essencialmente o cálculo destas características Haar. Em vez de computar em cada pixel, cria sub-retângulos e referências de matriz para cada um desses sub-retângulos. Estes são então utilizados para calcular as características de Haar."
      ],
      "metadata": {
        "id": "055GTa79RLyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1_dy_lV_6Ne8KSeOWoWB1kAw.webp](data:image/webp;base64,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)"
      ],
      "metadata": {
        "id": "8Fs1TNvqRXTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É importante notar que quase todas as características de Haar serão irrelevantes na detecção de objetos, porque as únicas características que são importantes são as do objeto. "
      ],
      "metadata": {
        "id": "kMUP1UGMRbBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treinando Adaboost"
      ],
      "metadata": {
        "id": "6Qej1IhuRuI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O Adaboost escolhe essencialmente as melhores características e forma os classificadores para as utilizar. Utiliza uma combinação de \"classificadores fracos\" para criar um \"classificador forte\" que o algoritmo pode utilizar para detectar objectos.\n",
        "\n",
        "Os classificadores fracos são criados movendo uma janela sobre a imagem de entrada, e calculando as características Haar para cada subseção da imagem. Esta diferença é comparada com um limiar de aprendizagem que separa os não-objetos dos objetos. Como estes são \"classificadores fracos\", é necessário um grande número de características de Haar para que a precisão constitua um classificador forte. A ultima etapa combina estes classificadores fracos com classificadores fortes usando classicadores em cascata."
      ],
      "metadata": {
        "id": "9oZmJ2QURyxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementando classificadores em cascata"
      ],
      "metadata": {
        "id": "f0BtRh-0SRca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O classificador em cascata é composto por uma série de etapas, onde cada etapa é um conjunto de classificadores fracos. Os classificadores fracos são treinados através do reforço, o que permite um classificador altamente preciso a partir da previsão média de todos os classificadores fracos.\n",
        "\n",
        "Com base nesta previsão, o classificador decide indicar que foi encontrado um objeto (positivo) ou passar para a região seguinte (negativo). As fases são concebidas para rejeitar amostras negativas tão rapidamente quanto possível, porque a maioria das janelas não contém nada de interesse. É importante maximizar uma taxa baixa de falsos negativos, porque a classificação de um objeto como não-objeto prejudicará gravemente o seu algoritmo de detecção de objetos. \n",
        "\n",
        "O Haar cascade é um dos muitos algoritmos que estão atualmente sendo utilizados para a detecção de objetos. Uma coisa a notar sobre Haar cascade é que é muito importante reduzir a taxa de falsos negativos, por isso deve-se de afinar os hiperparâmetros em conformidade quando treinar o modelo."
      ],
      "metadata": {
        "id": "2HC3kjIhSVOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Desenvolvimento"
      ],
      "metadata": {
        "id": "MHXiBZfLS7Up"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O trabalho a ser descrito abaixo trata-se da utilização do algoritmo Haar cascade, descrito acima, para a classificação de personagens da série de TV \"Eu, a patroa e as crianças\". Foi utilizado um pequeno recorte de um episódio da série e imagens dos personagens obtidas pelo Google Images. Os personagens a serem reconhecidos são: \"Michael Kyle\", \"Janet Kyle\", \"Claire Kyle\", \"Michael Kyle Junior\" e \"Kady Kyle\". Apenas o primeiro nome dos personagens foi utilizado para a identificação, sendo que o Michael Kyle Junior foi identificado apenas como Junior."
      ],
      "metadata": {
        "id": "UTYynhAxThjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bibliotecas utilizadas"
      ],
      "metadata": {
        "id": "FzboUssDS9y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a aplicação do Haar cascade, utilizamos algumas bibliotecas que ajudarão na classificação e manipulação do vídeo. As bibliotecas que utilizamos para a realização do trabalho foram: `OpenCv`,`Face Recognition`, `PIL` e `Numpy`."
      ],
      "metadata": {
        "id": "1VE5QLgHTDZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Criando encodings dos personagens a serem detectados"
      ],
      "metadata": {
        "id": "kx8mPoRwT5ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiramente, definimos a função `cria_conhecidos()`, função essa que cria e retorna os nomes de cada um dos personagens a serem reconhecidos e seus encodings, obtidos pela função `face_encodings()` da biblioteca Face Recognition. Como parâmetro da função `face_encodings()`, passamos apenas a imagem lida da pasta Know e criamos uma lista de encodings para cada um dos personagens. Ao total, foram utilizadas 5 imagens de cada um dos personagens para a extração dos encodings e treinamento do Haar cascade. Abaixo, temos o código da função `cria_conhecidos()`:\n",
        "\n",
        "\n",
        "```\n",
        "def cria_conhecidos():\n",
        "  michel_face_encoding = []\n",
        "  janet_face_encoding = []\n",
        "  claire_face_encoding = []\n",
        "  junior_face_encoding = []\n",
        "  kady_face_encoding = []\n",
        "\n",
        "  known_face_names = []\n",
        "\n",
        "  for i in range(1,6):\n",
        "    image_of_michel = face_recognition.load_image_file(f'./know/michel{i}.jpg')\n",
        "    michel_face_encoding.append(face_recognition.face_encodings(image_of_michel)[0])\n",
        "\n",
        "    image_of_janet = face_recognition.load_image_file(f'./know/janet{i}.jpg')\n",
        "    janet_face_encoding.append(face_recognition.face_encodings(image_of_janet)[0])\n",
        "\n",
        "    image_of_claire = face_recognition.load_image_file(f'./know/claire{i}.jpg')\n",
        "    claire_face_encoding.append(face_recognition.face_encodings(image_of_claire)[0])\n",
        "\n",
        "    image_of_junior = face_recognition.load_image_file(f'./know/junior{i}.jpg')\n",
        "    junior_face_encoding.append(face_recognition.face_encodings(image_of_junior)[0])\n",
        "\n",
        "    image_of_kady = face_recognition.load_image_file(f'./know/kady{i}.jpg')\n",
        "    kady_face_encoding.append(face_recognition.face_encodings(image_of_kady)[0])\n",
        "\n",
        "    known_face_names.extend([\"Michel\", \"Janet\", \"Claire\", \"Junior\", \"Kady\"])\n",
        "\n",
        "\n",
        "  #  Create arrays of encodings and names\n",
        "  known_face_encodings = [\n",
        "    michel_face_encoding,\n",
        "    janet_face_encoding,\n",
        "    claire_face_encoding,\n",
        "    junior_face_encoding,\n",
        "    kady_face_encoding\n",
        "  ]\n",
        "\n",
        "  return known_face_encodings, known_face_names\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "5koC1VC9UF7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Marcando as pessoas no frame do vídeo"
      ],
      "metadata": {
        "id": "YgAyACO5VMZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, definimos a função `marca_pessoas()`, que vai receber um frame do vídeo e identificar quais dos personagens conhecidos está presente no frame. Primeiramente, extraimos os face locations do frame, com a função `face_locations()` da biblioteca Face Recognition. Com esses face locations, passamos eles e a imagem como parâmetro para extrair o face encoding do frame, utilizando a função `face_encodings()`. Após isso, convertemos a imagem para uma imagem PIL (Python Imaging Library) e criamos uma instância Draw para que possamos marcar as pessoas na imagem. \n",
        "\n",
        "Por fim, percorremos cada um dos face encodings encontrados no frame e comparamos os face encondings encontrados com os face encodings já obtidos na função anteriormente explicada. Para isso é utilizado a função `compare_faces()`, também da biblioteca Face Recognition, que retorna uma lista de True/False, indicando se há um rosto conhecido na lista de encodings do frame. Caso haja, obtemos o nome da pessoa e desenhamos um box com o seu nome no seu rosto. Se um rosto for identificado mas o personagem não for reconhecido, o mesmo será rotulado como \"Unknow Person\". Por fim, retornamos a PIL image resultante para ser escrita como vídeo.\n",
        "\n",
        "Abaixo temos o código criado para realizar este procedimento:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def marca_pessoas(frame,known_face_encodings,known_face_names):\n",
        "  \n",
        "  # Find faces in test image\n",
        "  face_locations = face_recognition.face_locations(frame)\n",
        "  face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
        "\n",
        "  # Convert to PIL format\n",
        "  pil_image = Image.fromarray(frame)\n",
        "\n",
        "  # Create a ImageDraw instance\n",
        "  draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "  names = []\n",
        "\n",
        "  # Loop through faces in test image\n",
        "  for(top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.2)\n",
        "    # print(matches)\n",
        "    name = \"Unknown Person\"\n",
        "    # If match\n",
        "    if np.array(matches).any():\n",
        "      matchedIdxs = [b.sum() for b in matches]\n",
        "      counts = {}\n",
        "\n",
        "      i = np.argmax(np.array(matchedIdxs))\n",
        "      name = known_face_names[i]\n",
        "           \n",
        "    # Draw box\n",
        "    draw.rectangle(((left, top), (right, bottom)), outline=(255,255,0))\n",
        "\n",
        "    # Draw label\n",
        "    text_width, text_height = draw.textsize(name)\n",
        "    draw.rectangle(((left,bottom - text_height - 10), (right, bottom)), fill=(255,255,0), outline=(255,255,0))\n",
        "    draw.text((left + 6, bottom - text_height - 5), name, fill=(0,0,0))\n",
        "\n",
        "  del draw\n",
        "\n",
        "  return pil_image\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "xWrBG95rVUEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Criando o vídeo resultante"
      ],
      "metadata": {
        "id": "z-I5t3CCX55-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a criação do vídeo, primeiro obtemos os face encodings e os nomes dos personagens conhecidos, isto é feito inicialmente pois só há a necessidade de ser feito uma vez e as imagens dos personagens conhecidos são as mesmas, otimizando o processamento do frame. Após isso, criamos instâncias de video, utilizando as funções `VideoCapture()` e `VideoWriter()` da biblioteca OpenCV, para a obtenção do frame no vídeo e escrita do resultado, respectivamente. Após obtermos o frame, convertemos o mesmo para o espaço de cores RGB e marcamos os rostos presentes no frame. Com o resultado, convertemos novamente para o espaço BGR e escrevemos o frame no vídeo resultante, com o nome de `saida.avi`. É importante resaltar que não processamos todos os frames do vídeo original, pois a detecção de rostos é um processo custoso, então decidimos processar o vídeo original de 5 em 5 frames, utilizando métodos da OpenCV para obter a contagem total de frames e posicionar o vídeo no frame desejado.\n",
        "\n",
        "Abaixo temos o código, na função main, que realiza o procedimento:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "def main():\n",
        "  known_face_encodings,known_face_names = cria_conhecidos()\n",
        "  \n",
        "  EPC = cv2.VideoCapture('EPC-Pai-do-Ano.mp4')\n",
        "  \n",
        "  if (EPC.isOpened()== False): \n",
        "    print(\"Erro abertura da camera\")\n",
        "  i = 0\n",
        "\n",
        "  vid_writer=None\n",
        "\n",
        "  while(True):\n",
        "    # Take each frame\n",
        "    ret , frame = EPC.read()\n",
        "    frame_width = int(EPC.get(3))\n",
        "    frame_height = int(EPC.get(4))\n",
        "    \n",
        "    if vid_writer is None:\n",
        "      vid_writer = cv2.VideoWriter('saida.avi', cv2.VideoWriter_fourcc(*\"MJPG\"), 5, (frame_width,frame_height))\n",
        "\n",
        "    if ret:\n",
        "      frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)        \n",
        "      pil_image = marca_pessoas(frame, known_face_encodings, known_face_names)\n",
        "      # pil_image.save(str(i)+\".jpg\")\n",
        "      res = np.array(pil_image)\n",
        "      res = cv2.cvtColor(res,cv2.COLOR_RGB2BGR)  \n",
        "      vid_writer.write(res)\n",
        "    else:\n",
        "      break\n",
        "\n",
        "    \n",
        "    i += 1\n",
        "    \n",
        "    if 5*i < int(EPC.get(cv2.CAP_PROP_FRAME_COUNT)):\n",
        "      EPC.set(cv2.CAP_PROP_POS_FRAMES, 5*i)\n",
        "    else:\n",
        "      EPC.set(cv2.CAP_PROP_POS_FRAMES, int(EPC.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "    \n",
        "    print('Position:', int(EPC.get(cv2.CAP_PROP_POS_FRAMES)))\n",
        "  vid_writer.release()\n",
        "  cv2.destroyAllWindows()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zpgursvPX_BQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resultado"
      ],
      "metadata": {
        "id": "SbrzVyW3ZuTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nosso resultado foi um vídeo sem som, onde alguns dos personagens são destacados um um box em seus rostos e o seu nome escrito abaixo. Podemos verificar que o vídeo resultante parece estar travando, já que ele tem menos frames que o vídeo original. Outra coisa que é válido ressaltar é que muitas vezes alguns personagens estão presentes no vídeo mas não são reconhecidos. Isto se dá porque o algoritmo não conseguiu reconhecer o rosto daquele personagem, seja porque ele está de lado ou porque não se tem uma posição muito clara daquele personagem. O resultado pode ser visto no vídeo nomeado como `saida.avi`."
      ],
      "metadata": {
        "id": "NFKnwfw7ZwvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Considerações Finais"
      ],
      "metadata": {
        "id": "cHV4J9GTacm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O processamento das imagens retornou resultados satisfatórios, como pode ser observado no vídeo resultante. O reconhecimento de faces no vídeo retorna na maior parte do tempo o nome correto do personagem, com o box desenhado exatamente no seu rosto. Acreditamos que utilizar vídeos onde o personagem olhe mais precisamente para a câmera, sem que haja uma distorção no seu rosto, aumentaria bastante a precisão do algoritmo. Por fim, podemos afirmar que concluimos o objetivo de reconhecer e marcar os personagens da série \"Eu, a patroa e as crianças\", obtendo bons resultados mesmo num vídeo com baixa qualidade."
      ],
      "metadata": {
        "id": "JeisJ7rHafdo"
      }
    }
  ]
}